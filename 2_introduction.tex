\section{Introduction}
Text generation models have demonstrated promising real-world applications. One core issue of text generation is models often generate text that is unfaithful, untrue or even completely "hallucinated"~\cite{Rohrbach2018ObjectHI, maynez-etal-2020-faithfulness, Honovich2022TRUERF}. In terms of consistency types, we can divide evaluating hallucination into two purposes,~\emph{faithfulness} and \emph{factuality}. The two purposes are usually used for different tasks. As shown in~\todo{Figure 1}, faithfulness evaluates the consistency between the generated text and input documents for tasks, e.g.,~summarization~\cite{Nallapati2016AbstractiveTS}, OpenQA~\cite{Hermann2015TeachingMT}; factuality evaluates the consistency between the generated text and facts (or common sense) for tasks, e.g.,~common-sense QA~\cite{Zellers2018SWAGAL}. 